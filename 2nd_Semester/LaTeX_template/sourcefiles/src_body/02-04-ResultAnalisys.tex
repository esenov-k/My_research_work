\chapter{Анализ результатов обучения}

Для полноценной оценки обучения необходимо провести анализ метрик, полученных в
результате.

\section{График средней точности}

Начнем анализ с графика средней точности, представленного на рисунке 
\ref{fig::PrecisionRecall}.

\img[htb]{fig::PrecisionRecall}{Precision_Recall.png}{Кривая средней точности}
{0.9}

На графике видно, что классы, которые соответствуют наиболее популярным объектам
на дороге (автомобиль, микроавтобус, грузовик), показывают высокие значения 
средней точности --- это означает, что модель хорошо обнаруживает и правильно 
классифицирует данные объекты. Класс "Сидящий человек" имеет значительно более
низкое значение точности и полноты (0.553), что может указывать на то, что этот
класс труднее распознать, либо в датасете для обучения было меньше примеров таких
объектов. Среднее значение точности для всех классов (mAP@0.5) составляет 0.832,
что говорит о достаточно высоком общем качестве распознавания по всем классам.
Значение mAP@0.5 означает среднюю точность по всем классам при пороге полноты в 50%.

\section{График <<Полнота-Уверенность>>}

Далее рассмотрим график Полноты-Уверенности (Recall-Confidence) показанный на 
рисунке \ref{fig::RecallConfidence}.На графике показано, как меняется полнота
(recall) модели при изменении порога уверенности (confidence) для каждого класса.

\img[htb]{fig::RecallConfidence}{Recall_Confidence.png}{Кривая <<Полнота-Уверенность>>}
{0.9}

Исходя из результатов можем наблюдать, что модель хорошо справляется с обнаружением
автомобилей, микроавтобусов, грузовиков, поскольку кривые для этих классов высоки
даже при большой уверенности. Для классов с более низкими кривыми, например "Сидящий
человек", модель демонстрирует более низкую полноту, что может означать сложность в
обнаружении этих классов объектов.

Линия "Все классы" показывает совокупную эффективность модели по всем классам.
Высокий показатель полноты при нулевом пороге уверенности (0.93 при 0.000) указывает
на то, что в целом модель отлично справляется с обнаружением объектов, когда не
применяется порог отсечения.

\section{График <<Оценка F1-Уверенность>>}

На рисунке \ref{fig::F1Confidence} представлена кривая Оценка F1-Уверенность (F1-
Confidence). Оценка F1 — это гармоническое среднее между точностью и полнотой, и
она стремится к 1, когда и точность, и полнота высоки. Классы, чьи кривые ближе к
верхнему правому углу, обнаруживаются лучше. Рассчитывается следующим образом:
\[ F1 = 2/(1/precision + 1/recall) = TP/(TP+1/2*(FN+FP))\]

\img[htb]{fig::F1Confidence}{F1_Confidence.png}{Кривая <<Оценка F1-Уверенность>>}
{0.9}

Значение F1 = 0.81 при уверенности 0.320 говорит о достаточно высоком качестве 
обнаружения по всем классам в целом. Опять же, такие классы, как автомобиль,
микроавтобус, грузовик показывают высокие значения оценки F1, что указывает на их
отличную обнаруживаемость, в отличие от того же сидящего человека.

\section{График <<Точность-Уверенность>>}

Кривая Точность-Уверенность (Precision-Confidence) представлена на рисунке 
\ref{fig::PrecisionConfidence}. На нем показано, как меняется точность (precision)
модели при изменении порога уверенности (confidence) для каждого класса.

\img[htb]{fig::PrecisionConfidence}{Precision_Confidence.png}{Кривая <<Точность-
Уверенность>>}{0.9}

Исходя из графика, можно сделать следующие выводы: классы, такие как "Автомобиль",
показывают высокую точность даже при высоком уровне уверенности, что является
индикатором надежности модели. Синяя линия "Все классы" с показателем 1.00 при
Confidence 0.964 свидетельствует о высоком общем уровне точности для всех классов
при высоких порогах уверенности.

В целом, график указывает на то, что результаты модели хорошие, особенно если учитывать
высокий уровень Precision при высоких порогах Confidence. Это говорит о том, что модель
обучена и настроена довольно хорошо для идентификации объектов с большой уверенностью.
Однако всегда есть место для улучшения, особенно в отношении повышения точности при более
низких порогах уверенности, чтобы уменьшить количество ложных срабатываний и повысить
надежность системы в реальных условиях эксплуатации.

\section{Графики точности и потерь}

На рисунке \ref{fig::Results} представлено 10 графиков: 2 по ограничивающим рамкам, 2 по
потерям классификации, 2 по потери объектности, графики, отражающие точность и полноту, а
также по средней точности. 

\img[htb]{fig::Results}{Results.png}{Графики потерь и точности}{0.95}

\textbf{Потери ограничивающей рамки (box\_loss):}

Графики показывают, как потери, связанные с ограничивающими рамками объектов, уменьшаются как на тренировочном, так и на валидационном наборе данных по мере обучения.
Снижение этих потерь указывает на то, что модель становится лучше в точном определении местоположения объектов в изображении.

\textbf{Потери классификации (cls\_loss):}

Потери классификации также снижаются, что говорит о том, что модель улучшает свою способность правильно классифицировать объекты.

\textbf{Потери объектности (df1\_loss):}

Эти потери отражают уверенность модели в наличии объекта в ограничивающей рамке. Уменьшение этих потерь свидетельствует о том, что модель становится более уверенной в своих предсказаниях.

\textbf{Точность (precision) и полнота (recall):}

Увеличение этих метрик показывает, что модель становится более точной и полной в своих предсказаниях. Высокая точность означает, что большинство объектов, которые модель определяет как положительные, действительно являются положительными, а высокая полнота означает, что модель правильно идентифицирует большую часть положительных объектов.

\textbf{Средняя точность (mAP):}

mAP@0.5 и mAP@0.5-0.95 — это средние точности на различных порогах перекрытия. mAP@0.5 измеряет точность при IoU (пересечение по объединению) равном 0.5, а mAP@0.5-0.95 усредняет точность от IoU 0.5 до 0.95. Улучшение mAP свидетельствует о повышении общей точности модели по всему диапазону порогов IoU.

